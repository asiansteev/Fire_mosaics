---
title: "bird_gso_test"
author: "Chris Adlam"
date: "10/4/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F, error = F) 
knitr::knit_hooks$set(
   error = function(x, options) {
     paste('\n\n<div class="alert alert-danger">',
           gsub('##', '\n', gsub('^##\ Error', '**Error**', x)),
           '</div>', sep = '\n')
   },
   warning = function(x, options) {
     paste('\n\n<div class="alert alert-warning">',
           gsub('##', '\n', gsub('^##\ Warning:', '**Warning**', x)),
           '</div>', sep = '\n')
   },
   message = function(x, options) {
     paste('\n\n<div class="alert alert-info">',
           gsub('##', '\n', x),
           '</div>', sep = '\n')
   }
)
```

```{r include = F}
# Load packages
library(tidyverse)
library(emmeans)
library(lme4)
library(lmerTest)
library(pbkrtest)
library(car)
library(ggplot2)
library(cowplot)
library(reshape2)
library(splitstackshape)
library(magrittr)
library(readr)
library(vegan)
library(viridis)
library(cowplot)
library(purrr)
library(tibble)
library(broom)
library(labdsv)
library(indicspecies)
library(permute)
library(perm)
library(magrittr)
library(kableExtra)
library("knitr")
library(rowr)
#knit2html("Fire_mosaics.html")

```


```{r}
site_data_read <- read.csv("/Users/christopheradlam/Desktop/Davis/R/GitHub Repos/Fire_mosaics/Data/site_data.csv") 
site_data_read$tsf <- as.numeric(as.character(site_data_read$tsf))
site_data_read$fire_yr <- as.numeric(as.character(site_data_read$fire_yr))

# here I'm setting the TSF categories; change as necessary.
site_data <- site_data_read %>% 
    mutate(tsf_cat = ifelse(is.na(tsf), "4", "3"))
site_data$tsf_cat[site_data$tsf < 17] <-2
site_data$tsf_cat[site_data$tsf < 10] <-1

site_data$site_id <- as.character(site_data$site_id)

# read in data
bird_dat_suppl <- read.csv("data/bird_data_suppl.csv")
bird_dat_count <- read.csv("data/bird_data.csv", header = T) %>% 
  filter(DetectionLocationNm != "O") %>% # removing species outside (O) the stand
  dplyr::select(Point, Count, Spp, DistanceBin) # keeping only relevant columns

# remove duplicate rows (same species detected multiple times in a single plot)
bird_dat_long <- unique(bird_dat_count[ , c(1,3) ]) %>% 
  mutate(pa = 1) %>% 
  dplyr::rename(site_id = Point) %>% 
  dplyr::rename(species = Spp)


# Adding additional species detections (outside count)
bird_dat_long <- bind_rows(bird_dat_suppl, bird_dat_long)
```


```{r Read in data, eval=FALSE}
## Packages needed throughout
library (plyr)
library (dplyr)
library (reshape2)

# create list of all species
bird_spp <- bird_dat_long %>% 
  dplyr::select(species, pa)

bird_spp <-  unique(bird_spp[ , c(1,2)]) %>% 
  dplyr::select(species)

# Add site data to detection data
bird_dat_long$site_id <- as.character(bird_dat_long$site_id)
bird_dat_long <- left_join(bird_dat_long, site_data, by = "site_id")

## Unburnt data: filter to get only UN; keep only species and cover columns
bird_dat_UN <- bird_dat_long %>% 
  filter(sev == "u") %>% 
  dplyr::select(species, pa, site_id)  %>% 
  arrange(species)

# make it wide format
bird_dat_UN <- reshape(bird_dat_UN, idvar = "species", timevar = "site_id", direction = "wide")

# add species not detected to get same length vectors
ar.w <- full_join(bird_spp, bird_dat_UN, by = "species") %>% 
  replace(., is.na(.), "0")

## LS data (less than 14 yrs): filter to get only LS, TSF less than 14 years, keep only species and cover columns
bird_dat_LS1 <- bird_dat_long %>% 
  filter(sev == "l")

bird_dat_LS1$fire_yr <- as.character(bird_dat_LS1$fire_yr)
bird_dat_LS1$fire_yr <- as.numeric(bird_dat_LS1$fire_yr)
bird_dat_LS1$tsf <- 2018-bird_dat_LS1$fire_yr

bird_dat_LS1 <- bird_dat_LS1 %>% 
  filter(tsf < 14) %>% 
  dplyr::select(species, pa, site_id) %>% 
  arrange(species)
  
bird_dat_LS1 <- reshape(bird_dat_LS1, idvar = "species", timevar = "site_id", direction = "wide")

# add species not detected to get same length vectors
be.w <- full_join(bird_spp, bird_dat_LS1, by = "species") %>% 
  replace(., is.na(.), "0")

## LS data (less than 10 yrs; 11 sites total): filter to get only LS, TSF more than 10 years, keep only species and cover columns
bird_dat_LS2 <- bird_dat_long %>% 
  filter(sev == "l")

bird_dat_LS2$fire_yr <- as.character(bird_dat_LS2$fire_yr)
bird_dat_LS2$fire_yr <- as.numeric(bird_dat_LS2$fire_yr)
bird_dat_LS2$tsf <- 2018-bird_dat_LS2$fire_yr

bird_dat_LS2 <- bird_dat_LS2 %>% 
  filter(tsf < 10) %>% 
  dplyr::select(species, pa, site_id) %>% 
  arrange(species)
  
bird_dat_LS2 <- reshape(bird_dat_LS2, idvar = "species", timevar = "site_id", direction = "wide")

# add species not detected to get same length vectors
xx.w <- full_join(bird_spp, bird_dat_LS2, by = "species") %>% 
  replace(., is.na(.), "0")

# HS data (less than 11 yrs; 13 sites): filter to get only LS, TSF less than 10 years, keep only species and cover columns
bird_dat_HS1 <- bird_dat_long %>% 
  filter(sev == "h")

bird_dat_HS1$fire_yr <- as.character(bird_dat_HS1$fire_yr)
bird_dat_HS1$fire_yr <- as.numeric(bird_dat_HS1$fire_yr)
bird_dat_HS1$tsf <- 2018-bird_dat_HS1$fire_yr

bird_dat_HS1 <- bird_dat_HS1 %>% 
  filter(tsf < 11) %>% 
  dplyr::select(species, pa, site_id) %>% 
  arrange(species)

bird_dat_HS1 <- reshape(bird_dat_HS1, idvar = "species", timevar = "site_id", direction = "wide")

#bird_dat_LS11 

cm.w <- full_join(bird_spp, bird_dat_HS1, by = "species") %>% 
  replace(., is.na(.), "0")

# HS data (more than 10 yrs; 10 sites): filter to get only LS, TSF more than 10 years, keep only species and cover columns
bird_dat_HS2 <-bird_dat_long %>% 
  filter(sev == "h")

bird_dat_HS2$fire_yr <- as.character(bird_dat_HS2$fire_yr)
bird_dat_HS2$fire_yr <- as.numeric(bird_dat_HS2$fire_yr)
bird_dat_HS2$tsf <- 2018-bird_dat_HS2$fire_yr

bird_dat_HS2 <- bird_dat_HS2 %>% 
  filter(tsf > 10) %>% 
  dplyr::select(species, pa, site_id) %>% 
  arrange(species)

bird_dat_HS2 <- reshape(bird_dat_HS2, idvar = "species", timevar = "site_id", direction = "wide")

#bird_dat_HS22 

dl.w <- full_join(bird_spp, bird_dat_HS2, by = "species") %>% 
  replace(., is.na(.), "0")
```

Only run the following chunk if you need to convert abundance data to presence-absence.

```{r Convert abundance data to presence-absence, eval = FALSE}
convert <- function (x) {
  species <- x %>% dplyr::select (species)
  s <- x %>% dplyr::select(-species)
  df <-  data.frame(t(apply (as.matrix(s), 1, function (x) ifelse (x>0, 1, 0))))
  b <- bind_cols (species, df)
  return (b)}

ar.w <- convert (ar.w)
be.w <- convert (be.w)
xx.w <- convert (xx.w)
cm.w <- convert (cm.w)
dl.w <- convert (dl.w)
```

Convert the data format from wide to long (such that there are only three columns: species, site, value), and order by species. Then delete the site column.  

```{r Melt data, warning=FALSE, results="hide", eval = FALSE}
melt.sort <- function (x){
  m <- melt(x, id.vars="species") # convert to long
  s <- m[order(m$species),] # order by species
  s$variable <- NULL # delete site column
  return(s)}

# l = data are in long format
ar.l <- melt.sort(ar.w) %>% 
  mutate(value = as.numeric(value))
be.l <- melt.sort(be.w) %>% 
  mutate(value = as.numeric(value))
xx.l <- melt.sort(xx.w) %>% 
  mutate(value = as.numeric(value))
cm.l <- melt.sort(cm.w) %>% 
  mutate(value = as.numeric(value))
dl.l <- melt.sort(dl.w) %>% 
  mutate(value = as.numeric(value))

```

Now data are ready for resampling.  Use a different method for abundance data (resampling with replacement) and presence-absence data (random number generation from the binomial distribution).  Both methods produce a matrix named `zdata`.  

An extra step is required for data containing subsamples -- see below.

#### Abundance data

Use this method for abundance datasets which don't contain subsamples.

```{r Abundance, eval=FALSE}
res.ab <- function (z){(ddply (z, .(species), function(x) { 
  rs1 <- sample(x$value, replace = TRUE) # resample raw data
  bm <- mean(rs1) # big mean is the mean of the resampled means  
  data.frame(bm=bm)}
  ))
}

# Run 'res.ab' on each growth stage:
ar.r <- rdply (1000, res.ab (ar.l))
be.r <- rdply (1000, res.ab (be.l))
xx.r <- rdply (1000, res.ab (xx.l))
cm.r <- rdply (1000, res.ab (cm.l))
dl.r <- rdply (1000, res.ab (dl.l))

# Combine to a matrix:
zdata <- cbind (ar.r$.n, ar.r$bm, be.r$bm, xx.r$bm, cm.r$bm, dl.r$bm) # ar.r$.n = row labels
```

#### Presence-absence data

Use this method for presence-absence datasets which don't contain subsamples.

```{r Presence-absence, eval = FALSE}
res.pa <- function (z) {(ddply (z, .(species), function(x) { 
  mu <- mean (x$value)
  rn <- (rbinom (n = 1, size = length(x$value), prob = mu))/length(x$value) 
  # rn = random number based on mu
  data.frame(rn=rn)}
  ))
}

# Run 'res.pa' on each growth stage:
ar.r <- rdply (1000, res.pa (ar.l))
be.r <- rdply (1000, res.pa (be.l))
xx.r <- rdply (1000, res.pa (xx.l))
cm.r <- rdply (1000, res.pa (cm.l))
dl.r <- rdply (1000, res.pa (dl.l))

# Combine to a matrix:
zdata <- cbind (ar.r$.n, ar.r$rn, be.r$rn, xx.r$rn, cm.r$rn, dl.r$rn) # ar.r$.n = row labels
```

#### Alternative method for datasets containing subsamples.

Use the first method for abundance data and the second for presence-absence.  Edit `nrow` and `ncol` according to the number of sites (per GS) and the number of quadrats (per site).

```{r Subsamples: abundance data, eval = FALSE}
# Edit nrow and ncol according to numbers of subsamples/quadrats and sites
res.ab.s <- function (z) {(ddply (z, .(species), function(x) { 
  v <- matrix(x$value, nrow=7, ncol=3, byrow = FALSE) # nrow = quadrats, ncol = sites
  rs1 <- apply(v, 2, sample, replace = TRUE) # resample raw data
  mu1 <- apply (rs1, 2, mean) # take mean of each site's resampled data
  rs2 <- sample(mu1, replace=TRUE) # resample the means
  bm <- mean(rs2) # big mean is the mean of the resampled means  
  data.frame(bm=bm)}
  ))
}

# Run 'res.ab.s' on each growth stage:
ar.r <- rdply (1000, res.ab.s (ar.l))
be.r <- rdply (1000, res.ab.s (be.l))
cm.r <- rdply (1000, res.ab.s (cm.l))
dl.r <- rdply (1000, res.ab.s (dl.l))

# Combine to a matrix:
zdata <- cbind (ar.r$.n, ar.r$bm, be.r$bm, cm.r$bm, dl.r$bm) # ar.r$.n = row labels
```

```{r Subsamples: presence-absence data, eval = FALSE}
# Edit nrow and ncol according to numbers of subsamples/quadrats and sites
res.pa.s <- function (z) {(ddply (z, .(species), function(x) { 
  v <- matrix(x$value, nrow=10, ncol=3, byrow = FALSE) # nrow = quadrats, ncol = sites
  rb1 <- apply (v, 2, mean)
  mu <- rb1/length(rb1)
  rn <- (rbinom (n = 1, size = length(rb1), prob = mu))/length(rb1) # random number
  data.frame(rn=rn)}
  ))
}

# Run 'res.pa.s' on each growth stage:
ar.r <- rdply (1000, res.pa.s (ar.l))
be.r <- rdply (1000, res.pa.s (be.l))
cm.r <- rdply (1000, res.pa.s (cm.l))
dl.r <- rdply (1000, res.pa.s (dl.l))

# Then combine to a matrix:
zdata <- cbind (ar.r$.n, ar.r$rn, be.r$rn, cm.r$rn, dl.r$rn) # ar.r$.n = row labels
```


### Convert the matrix to a data frame and save it.

The same method applies to all data types from this point.

```{r Combine data, eval = FALSE}
mdata <- apply (zdata, 2, function (x) ifelse (x>0, x, 0.001)) 
# replace zeros for geometric mean calculation
rdata <- data.frame(mdata) # convert to a data frame
names(rdata) <- c("group", "AR", "BE", "XX", "CM", "DL")
rdata$group <- factor(rdata$group) # rdata is ready for the GSO function
```

***


## 2 Run the GSO function

The nloptr function maximises the geometric mean by changing the growth stage proportions given bounds constraints (parameters (GS proportions) must be between 0 and 1), and an inequality constraint -- the parameters must sum to 1. 

```{r GSO function, eval = FALSE, warning=FALSE}
library(nloptr)
library(plyr)
library(dplyr)
## Handy helper function, constructing a n-length vector c(k, ..., k)
const.vector <- function(n, k) {
  return( sapply(seq_len(n), function (x) return(k)) )
}
## The original objective (assumes columns [AR, BE, CM, DL] appear in that order) 
geomean.fun <- function(x, species) {
  logsum <- sum(log(apply(species, 1, function (row) { sum(x*row) })))
  exp(logsum/(dim(species)[1]))
}
## The reformulated objective (nloptr expects a minimization problem)
geomean.obj <- function (x, species) {
  logsum <- sum(log(apply(species, 1, function (row) { sum(x*row) })))
  return(-logsum)
}
## The gradient of geomean.obj.
## Returns a vector containing the partial derivatives wrt each var.
geomean.grad <- function(x, species) {
  contrib <- apply(species, 1, function(row) { -row/(sum(x*row)) })
  grad <- apply(contrib, 1, sum)  # sum the contribution vectors to get the gradient
  return(grad)
}
## Inequality constraints.
eval.cs <- function(x, species) {
  return( c(
    sum(x) - 1,  # Growth stage proportions don't exceed 1
    0.0 - x[1]   # Recently burnt proportion is at least 0.0 (i.e. AR >= 0.0)
  ))
}
eval.cs.jac <- function(x, species) { # Jacobian (partial derivative matrix) for inequalities
  return( rbind(
    const.vector(length(x), 1),
    c(-1, const.vector(length(x)-1, 0))
    ))
}
## Pass all to nloptr 
gso <- function(species){
  require(nloptr)
  require(dplyr)
  x0 <- const.vector(5, 1/5)  # edit according to the number of growth stages
  run <- nloptr(x0 = x0, species = species, eval_f=geomean.obj, eval_grad_f = geomean.grad,
                lb = const.vector(length(x0), 0),
                ub = const.vector(length(x0), 1),
                eval_g_ineq = eval.cs,
                eval_jac_g_ineq = eval.cs.jac,
                opts = list("algorithm" = "NLOPT_LD_MMA",
                            "maxeval"=1000,
                            "ftol_rel"=1.0e-15,
                            "xtol_rel"=1.0e-8,
                            "print_level"=0
                            ))
  res <- rbind(c(run$solution, geomean.fun(run$solution, species)))
  colnames(res) <- c("AR", "BE", "XX", "CM", "DL", "geom") # edit according to growth stages
  res <- data.frame(res)
  return (res)
}

# Apply to the 1000 resampled communities (defined by group)
out <- ddply(rdata[2:6], .(rdata$group), gso) # takes a few minutes to run

# Or apply to a single community (for example, the raw data)
#out <- gso (rdata)

write.table (out, "gso_result.txt", col.names=TRUE, row.names=FALSE)
```


```{r GSO function, eval = FALSE, warning=FALSE}
# BROKEN
library(nloptr)
library(plyr)
library(dplyr)
## Handy helper function, constructing a n-length vector c(k, ..., k)
const.vector <- function(n, k) {
  return(sapply(seq_len(n), function(x) return(k)))
}
## The original objective (assumes columns [AR, BE, CM, DL] appear in that order)
geomean.fun <- function(x, species) {
  logsum <- sum(log(apply(species, 1, function(row) {
    sum(x * row)
  })))
  exp(logsum / (dim(species)[1]))
}
## The reformulated objective (nloptr expects a minimization problem)
geomean.obj <- function(x, species) {
  logsum <- sum(log(apply(species, 1, function(row) {
    sum(x * row)
  })))
  return(-logsum)
}
## The gradient of geomean.obj.
## Returns a vector containing the partial derivatives wrt each var.
geomean.grad <- function(x, species) {
  contrib <- apply(species, 1, function(row) {
    -row / (sum(x * row))
  })
  grad <- apply(contrib, 1, sum) # sum the contribution vectors to get the gradient
  return(grad)
}
## Inequality constraints.
eval.cs <- function(x, species) {
  return(c(
    sum(x) - 1, # Growth stage proportions don't exceed 1
    0.0 - x[1] # Recently burnt proportion is at least 0.0 (i.e. AR >= 0.0)
  ))
}
eval.cs.jac <- function(x, species) { # Jacobian (partial derivative matrix) for inequalities
  return(rbind(
    const.vector(length(x), 1),
    c(-1, const.vector(length(x) - 1, 0))
  ))
}
## Pass all to nloptr
gso <- function(species) {
  require(nloptr)
  require(dplyr)
  x0 <- const.vector(4, 1 / 4) # edit according to the number of growth stages
  run <- nloptr(
    x0 = x0, species = species, eval_f = geomean.obj, eval_grad_f = geomean.grad,
    lb = const.vector(length(x0), 0),
    ub = const.vector(length(x0), 1),
    eval_g_ineq = eval.cs,
    eval_jac_g_ineq = eval.cs.jac,
    opts = list(
      "algorithm" = "NLOPT_LD_MMA",
      "maxeval" = 1000,
      "ftol_rel" = 1.0e-15,
      "xtol_rel" = 1.0e-8,
      "print_level" = 0
    )
  )
  res <- rbind(c(run$solution, geomean.fun(run$solution, species)))
  colnames(res) <- c("A", "B", "C", "D", "geom") # edit according to growth stages
  res <- data.frame(res)
  return(res)
}

# Apply to the 1000 resampled communities (defined by group)

out <- ddply(test[2:4], .(test$group), gso) # takes a few minutes to run

# Or apply to a single community (for example, the raw data)
out <- gso(test)

write.table(out, "gso_result.txt", col.names = TRUE, row.names = FALSE)
```

If `gso` is applied to 1000 resampled datasets, the object `out` contains 1000 results (optimal growth stage structures and geometric means).  The mean and 95% confidence intervals can be derived from this distribution of values. 

***
